{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b75b26a5",
   "metadata": {
    "id": "uSVAbaSEPGhV"
   },
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "345ca269",
   "metadata": {
    "id": "-ld3FjNIoPaq"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('font', family='NanumBarunGothic') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed3e6713",
   "metadata": {
    "id": "xfotaSx_XOfQ"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "import torch \n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "from torchvision.io import read_image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn import preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3609af4a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98,
     "referenced_widgets": [
      "6782ca85017a4e1c8e3dde04cf8e68eb",
      "8d7eb1dd06ca4e9b97b3f294a251a39e",
      "99f06a29b12944edb068ad78652b6dbb",
      "df97ff99c0e24a91bab506c841896ed4",
      "cc59e4e822f1487da0e097855e6b9fd4",
      "303c412cbaa24a0c853b991b611c37dc",
      "00efd05984064462bcb5e6aca11922f6",
      "75b74cb7ca2b4d7f8338a57b0b7e25bf"
     ]
    },
    "id": "5Xctry3sXbQu",
    "outputId": "a261ccf3-8e9b-47f0-8865-c214d92004c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72d54f49",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HE1VxqfOcVIO",
    "outputId": "3c158251-aca3-4813-aa42-4c9412519898"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224\n"
     ]
    }
   ],
   "source": [
    "model_name = 'efficientnet-b0'\n",
    "image_size = EfficientNet.get_image_size(model_name)\n",
    "print(image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f860eb68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gTWeeIPL5UUz",
    "outputId": "423981c9-1a5c-40de-9f38-cc69c0c036a6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "model = EfficientNet.from_pretrained(model_name, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52398b64",
   "metadata": {
    "id": "SUrfX8m1Xn07"
   },
   "source": [
    "# Load tofu datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4b33040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TofuDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file, encoding='cp949')\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)        \n",
    "        if self.target_transform:\n",
    "            label = self.target_transform.transform([label])[0]\n",
    "\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2228564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_contrast_normalization(x: torch.tensor, scale='l2'):\n",
    "    \"\"\"\n",
    "    Apply global contrast normalization to tensor, i.e. subtract mean across features (pixels) and normalize by scale,\n",
    "    which is either the standard deviation, L1- or L2-norm across features (pixels).\n",
    "    Note this is a *per sample* normalization globally across features (and not across the dataset).\n",
    "    \"\"\"\n",
    "\n",
    "    assert scale in ('l1', 'l2')\n",
    "\n",
    "    n_features = int(np.prod(x.shape))\n",
    "    \n",
    "    x = x.float()\n",
    "\n",
    "    mean = torch.mean(x)  # mean over all features (pixels) per sample\n",
    "    x -= mean\n",
    "\n",
    "    if scale == 'l1':\n",
    "        x_scale = torch.mean(torch.abs(x))\n",
    "\n",
    "    if scale == 'l2':\n",
    "        x_scale = torch.sqrt(torch.sum(x ** 2)) / n_features\n",
    "\n",
    "    x /= x_scale\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "95abb0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-computed min and max values (after applying GCN) from train data per class\n",
    "min_ = - 4.4943\n",
    "max_ = 2.3380"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4ce66396",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                                transforms.Lambda(lambda x: global_contrast_normalization(x, scale='l1')),\n",
    "                                transforms.Normalize([min_],\n",
    "                                                     [max_ - min_])\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "75912778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = ['정상A', '정상B', '금속', '머리카락', '벌레', '상단불량D', '상단불량E', '유바', '탄화물', '플라스틱']\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "72f1a392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '금속',\n",
       " 1: '머리카락',\n",
       " 2: '벌레',\n",
       " 3: '상단불량D',\n",
       " 4: '상단불량E',\n",
       " 5: '유바',\n",
       " 6: '정상A',\n",
       " 7: '정상B',\n",
       " 8: '탄화물',\n",
       " 9: '플라스틱'}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_name_mapping = dict(zip(le.transform(le.classes_),le.classes_))\n",
    "le_name_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6282bda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_transform = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9402246a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.transform(['정상A'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8f9b2c2f",
   "metadata": {
    "id": "7YjEpDYJWdEt"
   },
   "outputs": [],
   "source": [
    "train_dataset = TofuDataset('../train_annotations.csv', '/workspace/TOFU_Kaier/DB/TOFU_BOX_margin/train', transform, target_transform )\n",
    "valid_dataset = TofuDataset('../valid_annotations.csv', '/workspace/TOFU_Kaier/DB/TOFU_BOX_margin/valid', transform, target_transform)\n",
    "test_dataset = TofuDataset('../test_annotations.csv', '/workspace/TOFU_Kaier/DB/TOFU_BOX_margin/test', transform, target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "867654b0",
   "metadata": {
    "id": "Y5f3auaTX5St"
   },
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "dataloaders = {}\n",
    "dataloaders['train'] = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=0)\n",
    "dataloaders['valid'] = DataLoader(valid_dataset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=0)\n",
    "dataloaders['test'] = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                        shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "33d785fe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZCy6TfTa7c9n",
    "outputId": "7d21fa44-4dd7-470b-f711-a33c3a4bc7e7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 640, 640])\n",
      "tensor([6, 6, 2, 0, 2, 7, 6, 6, 3, 4, 0, 8, 6, 7, 9, 1, 2, 6, 6, 0, 6, 0, 7, 3,\n",
      "        6, 6, 7, 7, 3, 6, 4, 6, 6, 6, 7, 6, 6, 4, 7, 7, 0, 1, 6, 8, 7, 7, 4, 7,\n",
      "        3, 6, 6, 6, 7, 9, 7, 6, 7, 6, 3, 6, 6, 8, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "#check dataloader shape\n",
    "for img, label in dataloaders['train']:\n",
    "    print(img.shape)\n",
    "    print(label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0302edb3",
   "metadata": {
    "id": "HWRYOujW9IR9"
   },
   "source": [
    "# Efficientnet transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "76b5832d",
   "metadata": {
    "id": "jaP9O8Ty8UTf"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    train_loss, train_acc, valid_loss, valid_acc = [], [], [], []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss, running_corrects, num_cnt = 0.0, 0, 0\n",
    "            \n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                num_cnt += len(labels)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            \n",
    "            epoch_loss = float(running_loss / num_cnt)\n",
    "            epoch_acc  = float((running_corrects.double() / num_cnt).cpu()*100)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_loss.append(epoch_loss)\n",
    "                train_acc.append(epoch_acc)\n",
    "            else:\n",
    "                valid_loss.append(epoch_loss)\n",
    "                valid_acc.append(epoch_acc)\n",
    "            print('{} Loss: {:.2f} Acc: {:.1f}'.format(phase, epoch_loss, epoch_acc))\n",
    "           \n",
    "            # deep copy the model\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_idx = epoch\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "#                 best_model_wts = copy.deepcopy(model.module.state_dict())\n",
    "                print('==> best model saved - %d / %.1f'%(best_idx, best_acc))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best valid Acc: %d - %.1f' %(best_idx, best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    torch.save(model.state_dict(), 'GCN_efficientnet_b0_president_model.pt')\n",
    "    print('model saved')\n",
    "    return model, best_idx, best_acc, train_loss, train_acc, valid_loss, valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e46e589f",
   "metadata": {
    "id": "UFQYk-tM_zdN"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # set gpu\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = optim.Adam(model.parameters(), \n",
    "                         lr = 1e-4)\n",
    "\n",
    "lmbda = lambda epoch: 0.98739\n",
    "exp_lr_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer_ft, lr_lambda=lmbda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c2e247df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gIAygUDiD3pQ",
    "outputId": "8de0a258-915a-4e21-f328-d9228dcf26fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.34 GiB (GPU 0; 15.75 GiB total capacity; 12.75 GiB already allocated; 1.91 GiB free; 12.77 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-83b5344bfff7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-125-db59f62c80eb>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;31m# track history if only in train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/efficientnet_pytorch/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \"\"\"\n\u001b[1;32m    313\u001b[0m         \u001b[0;31m# Convolution layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0;31m# Pooling and final linear layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_avg_pooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/efficientnet_pytorch/model.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdrop_connect_rate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mdrop_connect_rate\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blocks\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# scale drop connect_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_connect_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_connect_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;31m# Head\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/efficientnet_pytorch/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, drop_connect_rate)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expand_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bn0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depthwise_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/efficientnet_pytorch/utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mMemoryEfficientSwish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSwishImplementation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/efficientnet_pytorch/utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.34 GiB (GPU 0; 15.75 GiB total capacity; 12.75 GiB already allocated; 1.91 GiB free; 12.77 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "model, best_idx, best_acc, train_loss, train_acc, valid_loss, valid_acc = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43873136",
   "metadata": {
    "id": "KNKcGwnFkEyj"
   },
   "outputs": [],
   "source": [
    "## 결과 그래프 그리기\n",
    "print('best model : %d - %1.f / %.1f'%(best_idx, valid_acc[best_idx], valid_loss[best_idx]))\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.plot(train_acc, 'b-')\n",
    "ax1.plot(valid_acc, 'r-')\n",
    "plt.plot(best_idx, valid_acc[best_idx], 'ro')\n",
    "ax1.set_xlabel('epoch')\n",
    "# Make the y-axis label, ticks and tick labels match the line color.\n",
    "ax1.set_ylabel('acc', color='k')\n",
    "ax1.tick_params('y', colors='k')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(train_loss, 'g-')\n",
    "ax2.plot(valid_loss, 'k-')\n",
    "plt.plot(best_idx, valid_loss[best_idx], 'ro')\n",
    "ax2.set_ylabel('loss', color='k')\n",
    "ax2.tick_params('y', colors='k')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2e290d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dw1ClkRFj7EL",
    "outputId": "e68c9ac4-a427-4daa-da77-5ff31724df66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load saved model weights\n",
    "model_path = '/content/drive/MyDrive/Kaier_Tofu_Data/Regional attention/raw_data_president_model.pt'\n",
    "model_dict = torch.load(model_path)\n",
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628bf861",
   "metadata": {
    "id": "n4YbakC9jrK7"
   },
   "outputs": [],
   "source": [
    "def test(model, phase = 'test'):\n",
    "    # phase = 'train', 'valid', 'test'\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    running_loss, running_corrects, num_cnt = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predict_label_list = []\n",
    "        for i, (inputs, labels) in tqdm(enumerate(dataloaders[phase])):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)  # batch의 평균 loss 출력\n",
    "\n",
    "            running_loss    += loss.item() * inputs.size(0)\n",
    "            running_corrects+= torch.sum(preds == labels.data)\n",
    "            num_cnt += inputs.size(0)  # batch size\n",
    "\n",
    "            predict_label_list += (preds.cpu().tolist())\n",
    "  \n",
    "          \n",
    "\n",
    "            # if i == 2: break\n",
    "\n",
    "        test_loss = running_loss / num_cnt\n",
    "        test_acc  = running_corrects.double() / num_cnt       \n",
    "        print('test done : loss/acc : %.2f / %.1f' % (test_loss, test_acc*100))\n",
    "\n",
    "    return predict_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69fdbfd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZTCBeQnbk3XY",
    "outputId": "a4ccb9fc-2216-4021-dda7-c68862f7e6c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "131it [00:15,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test done : loss/acc : 1.05 / 87.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predict_label_list = test(model, phase = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bcce34",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-SWxUeWlmB_5",
    "outputId": "3ba2d157-a128-4bc3-eed5-dfcbf4531c90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'금속': 0.77,\n",
       " '머리카락': 0.9923076923076923,\n",
       " '벌레': 0.88,\n",
       " '상단불량D': 0.6784660766961652,\n",
       " '상단불량E': 0.9344262295081968,\n",
       " '유바': 0.9166666666666666,\n",
       " '정상A': 0.9237113402061856,\n",
       " '정상B': 0.8643649815043156,\n",
       " '탄화물': 0.7295081967213115,\n",
       " '플라스틱': 0.89}"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class별 accuracy \n",
    "class_names = ['정상A', '정상B', '금속', '머리카락', '벌레', '상단불량D', '상단불량E', '유바', '탄화물', '플라스틱']\n",
    "class_accuracy = dict()\n",
    "for class_ in class_names:\n",
    "  idx = np.in1d(test_class, class_)\n",
    "  class_tmp = (test_label==predict_label_list)[idx]\n",
    "  accruacy_ = np.sum(class_tmp) / len(class_tmp)\n",
    "  class_accuracy[class_] = accruacy_\n",
    "class_accuracy\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80912db",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "LYJcvDbcYjxd",
    "outputId": "409281aa-5a34-4439-c737-3743f963bc0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '금속',\n",
       " 1: '머리카락',\n",
       " 2: '벌레',\n",
       " 3: '상단불량D',\n",
       " 4: '상단불량E',\n",
       " 5: '유바',\n",
       " 6: '정상A',\n",
       " 7: '정상B',\n",
       " 8: '탄화물',\n",
       " 9: '플라스틱'}"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_name_mapping = dict(zip(le.transform(le.classes_),le.classes_))\n",
    "le_name_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598450aa",
   "metadata": {
    "id": "Gy3E2o2yNJxK"
   },
   "outputs": [],
   "source": [
    "predict_class_list = [le_name_mapping[x] for x in predict_label_list]\n",
    "test_class_list = [le_name_mapping[x] for x in test_label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c28436",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z23JefWLJ6HV",
    "outputId": "879b786c-1519-43af-9ffa-06b150264c3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-plot\n",
      "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (3.2.2)\n",
      "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (0.22.2.post1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.19.5)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n",
      "Installing collected packages: scikit-plot\n",
      "Successfully installed scikit-plot-0.3.7\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e881b2e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oxj_nz4prLDF",
    "outputId": "4d8bd032-498f-45a4-d7ea-f1084580a2a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 224, 224])"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10be4eed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "b81DNkWuonHo",
    "outputId": "99eab7fd-cb16-4b5f-82d0-709e0cd2ab08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64, 1280, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "print(img.shape)\n",
    "features = model.extract_features(img.cuda())\n",
    "print(features.shape)  "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pytorch efficientnet.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00efd05984064462bcb5e6aca11922f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "303c412cbaa24a0c853b991b611c37dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6782ca85017a4e1c8e3dde04cf8e68eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_99f06a29b12944edb068ad78652b6dbb",
       "IPY_MODEL_df97ff99c0e24a91bab506c841896ed4"
      ],
      "layout": "IPY_MODEL_8d7eb1dd06ca4e9b97b3f294a251a39e"
     }
    },
    "75b74cb7ca2b4d7f8338a57b0b7e25bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d7eb1dd06ca4e9b97b3f294a251a39e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99f06a29b12944edb068ad78652b6dbb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_303c412cbaa24a0c853b991b611c37dc",
      "max": 21388428,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cc59e4e822f1487da0e097855e6b9fd4",
      "value": 21388428
     }
    },
    "cc59e4e822f1487da0e097855e6b9fd4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "df97ff99c0e24a91bab506c841896ed4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75b74cb7ca2b4d7f8338a57b0b7e25bf",
      "placeholder": "​",
      "style": "IPY_MODEL_00efd05984064462bcb5e6aca11922f6",
      "value": " 20.4M/20.4M [00:00&lt;00:00, 93.1MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
